

@inproceedings{Rashtchian:2010kx,
  address =       {Los Angeles, CA},
  author =        {Cyrus Rashtchian and Peter Young and Micah Hodosh and
                   Julia Hockenmaier},
  booktitle =     {Proceedings of the {NAACL HLT} 2010 {W}orkshop on
                   creating speech and language data with {Amazon's
                   Mechanical Turk}},
  month =         {6 June},
  publisher =     {North American Chapter of the Association for
                   Computational Linguistics (NAACL)},
  title =         {Collecting Image Annotations Using {Amazon's
                   Mechanical Turk}},
  year =          {2010},
}

@unpublished{Cooperinprepa,
  author =        {Robin Cooper},
  note =          {Draft of book chapters available from
  \url{https://sites.google.com/site/typetheorywithrecords/drafts}},
  title =         {Type theory and language: from perception to
                   linguistic communication},
  year =          {in prep},
  url =           {https://sites.google.com/site/typetheorywithrecords/drafts},
}

@incollection{Dobnik:2013vn,
  address =       {Berlin, Heidelberg},
  author =        {Dobnik, Simon and Cooper, Robin and Larsson, Staffan},
  booktitle =     {Constraint Solving and Language Processing - 7th
                   International Workshop on Constraint Solving and
                   Language Processing, CSLP 2012, Orleans, France,
                   September 13-14, 2012. Revised Selected Papers},
  editor =        {Denys Duchier and Yannick Parmentier},
  number =        {8114},
  publisher =     {Springer},
  series =        {Publications on Logic, Language and Information
                   (FoLLI)},
  title =         {Modelling language, action, and perception in Type
                   Theory with Records},
  year =          {2013},
}

@article{Larsson:2015aa,
  author =        {Larsson, Staffan},
  journal =       {Journal of Logic and Computation},
  number =        {2},
  pages =         {335--369},
  title =         {Formal semantics for perceptual classification},
  volume =        {25},
  year =          {2015},
  abstract =      {A formal semantics for low-level perceptual aspects
                   of meaning is presented, tying these together with
                   the logical-inferential aspects of meaning
                   traditionally studied in formal semantics. The key
                   idea is to model perceptual meanings as classifiers
                   of perceptual input. Furthermore, we show how
                   perceptual aspects of meaning can be updated as a
                   result of observing language use in interaction,
                   thereby enabling fine-grained semantic plasticity and
                   semantic coordination. This requires a framework
                   where intensions are (i) represented independently of
                   extensions, and (ii) structured objects which can be
                   modified as a result of learning. We use Type Theory
                   with Records (TTR), a formal semantics framework that
                   starts from the idea that information and meaning is
                   founded on our ability to perceive and classify the
                   world, i.e. to perceive objects and situations as
                   being of types. As an example of our approach, we
                   show how a simple classifier of spatial information
                   based on the Perceptron can be cast in TTR.},
  doi =           {10.1093/logcom/ext059},
}

@article{Cooper:2015aa,
  author =        {Cooper, Robin and Dobnik, Simon and Lappin, Shalom and
                   Larsson, Staffan},
  journal =       {Linguistic Issues in Language Technology --- {LiLT}},
  month =         {November},
  number =        {4},
  pages =         {1--43},
  title =         {Probabilistic Type Theory and Natural Language
                   Semantics},
  volume =        {10},
  year =          {2015},
  url =           {https://gup.ub.gu.se/publication/226922},
}

@article{Dobnik:2016ad,
  author =        {Dobnik, Simon and Cooper, Robin},
  journal =       {Journal of Language Modelling},
  number =        {2},
  pages =         {273--301},
  title =         {Interfacing Language, Spatial Perception and
                   Cognition in {T}ype {T}heory with {R}ecords},
  volume =        {5},
  year =          {2017},
  url =           {https://gup.ub.gu.se/publication/251413},
}

@article{Harnad:1990,
  author =        {Harnad, Stevan},
  journal =       {Physica D},
  month =         {June},
  number =        {1--3},
  pages =         {335--346},
  title =         {The symbol grounding problem},
  volume =        {42},
  year =          {1990},
  doi =           {10.1016/0167-2789(90)90087-6},
}

@article{Roy:2002,
  author =        {Roy, Deb},
  journal =       {Computer speech and language},
  number =        {3},
  pages =         {353--385},
  title =         {Learning visually-grounded words and syntax for a
                   scene description task},
  volume =        {16},
  year =          {2002},
  abstract =      {A spoken language generation system has been
                   developed that learns to describe objects in
                   computer-generated visual scenes. The system is
                   trained by a show-and-tell' procedure in which visual
                   scenes are paired with natural language descriptions.
                   Learning algorithms acquire probabilistic structures
                   which encode the visual semantics of phrase
                   structure, word classes, and individual words. Using
                   these structures, a planning algorithm integrates
                   syntactic, semantic, and contextual constraints to
                   generate natural and unambiguous descriptions of
                   objects in novel scenes. The system generates
                   syntactically well-formed compound adjective noun
                   phrases, as well as relative spatial clauses. The
                   acquired linguistic structures generalize from
                   training data, enabling the production of novel word
                   sequences which were never observed during training.
                   The output of the generation system is synthesized
                   using word-based concatenative synthesis drawing from
                   the original training speech corpus. In evaluations
                   of semantic comprehension by human judges, the
                   performance of automatically generated spoken
                   descriptions was comparable to human-generated
                   descriptions. This work is motivated by our long-term
                   goal of developing spoken language processing systems
                   which grounds semantics in machine perception and
                   action.},
}

@inproceedings{Lowe:1999aa,
  author =        {Lowe, David G},
  booktitle =     {Computer vision, 1999. The proceedings of the seventh
                   IEEE international conference on},
  organization =  {IEEE},
  pages =         {1150--1157},
  title =         {Object recognition from local scale-invariant
                   features},
  volume =        {2},
  year =          {1999},
  doi =           {10.1109/ICCV.1999.790410},
}

@inproceedings{Karpathy:2015aa,
  author =        {Karpathy, Andrej and Fei-Fei, Li},
  booktitle =     {Proceedings of the IEEE Conference on Computer Vision
                   and Pattern Recognition},
  pages =         {3128--3137},
  title =         {Deep visual-semantic alignments for generating image
                   descriptions},
  year =          {2015},
}

@unpublished{Vedaldi:2016aa,
  author =        {Vedaldi, Andrea},
  month =         {March},
  note =          {iV\&L summer school on vision and language, Malta.
  http://www.robots.ox.ac.uk/$\sim$vedaldi/assets/teach/vedaldi16deepcv.pdf},
  title =         {Convolutional Networks for Computer Vision
                   Applications},
  year =          {2016},
  url =           {http://www.robots.ox.ac.uk/~vedaldi/assets/teach/
                  vedaldi16deepcv.pdf},
}

@inproceedings{Elliott:2013aa,
  author =        {Elliott, Desmond and Keller, Frank},
  booktitle =     {EMNLP},
  pages =         {1292--1302},
  title =         {Image Description using Visual Dependency
                   Representations},
  volume =        {13},
  year =          {2013},
}

@inproceedings{Mitchell:2013aa,
  author =        {Mitchell, Margaret and van Deemter, Kees and
                   Reiter, Ehud},
  booktitle =     {HLT-NAACL},
  pages =         {1174--1184},
  title =         {Generating Expressions that Refer to Visible Objects},
  year =          {2013},
}

@article{DaleReiter:1995,
  author =        {Dale, Robert and Reiter, Ehud},
  journal =       {Cognitive science},
  number =        {2},
  pages =         {233--263},
  title =         {Computational interpretations of the {G}ricean maxims
                   in the generation of referring expressions},
  volume =        {19},
  year =          {1995},
}

@article{Xu:2015aa,
  author =        {Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and
                   Courville, Aaron and Salakhutdinov, Ruslan and
                   Zemel, Richard and Bengio, Yoshua},
  journal =       {arXiv},
  month =         {February 11},
  pages =         {1--22},
  title =         {Show, attend and tell: Neural image caption
                   generation with visual attention},
  volume =        {arXiv:1502.03044 [cs.LG]},
  year =          {2015},
}

@inproceedings{Andreas:2016aa,
  address =       {San Diego, California},
  author =        {Jacob Andreas and Marcus Rohrbach and Trevor Darrell and
                   Dan Klein},
  booktitle =     {Proceedings of {NAACL-HLT} 2016},
  journal =       {CoRR},
  month =         {June 12-17},
  organization =  {Association for Computational Linguistics},
  pages =         {1545--1554},
  title =         {Learning to Compose Neural Networks for Question
                   Answering},
  year =          {2016},
  url =           {http://arxiv.org/abs/1601.01705},
}

@mastersthesis{Graaf:2016aa,
  address =       {Gothenburg, Sweden},
  author =        {de Graaf, Erik},
  month =         {June, 8th},
  note =          {{S}upervisor: Simon Dobnik, examiner: Richard
                   Johansson, opponent: Lorena Llozhi},
  school =        {Department of Philosophy, Linguistics and Theory of
                   Science. University of Gothenburg},
  title =         {Learning Objects and Spatial Relations with {K}inect},
  year =          {2016},
  abstract =      {In order for humans to have meaningful interactions
                   with a robotic system, this system should be capable
                   of grounding semantic representations to their
                   real-world representations, learn spatial
                   relationships and communicate using spoken human
                   language. End users need to be able to query the
                   system what objects it already has knowledge of, for
                   more efficient learning. Such systems exist, but
                   require large sample sizes, thus not allowing end
                   users to teach the system more objects when needed.
                   To overcome this problem, we developed a non-mobile
                   system dubbed Kille, that uses a 3D camera, SIFT
                   features and machine learning to allow a tutor to
                   teach the system objects and spatial relations. The
                   system is built upon the ROS (Robot Operating System)
                   framework and uses Opendial software as a dialogue
                   system, for which a ROS support was written as part
                   of this project. We describe the hardware of the
                   system, the software used and developed, and we
                   evaluate its performance. Our results show that Kille
                   performs well on small learning sets, considering the
                   low sample size it uses to learn. In contrast to
                   other approaches, we focus on learning by a tutor
                   presenting objects and not by providing a dataset.
                   Recognition of spatial relations works well, however
                   no definitive conclusions can be drawn. This is
                   largely due to the small number of participants and
                   the subjective nature of spatial relations.},
}

@inproceedings{Dobnik:2017aa,
  address =       {Gothenburg, Sweden},
  author =        {Dobnik, Simon and de Graaf, Erik},
  booktitle =     {Proceedings of the 21st Nordic Conference on
                   Computational Linguistics (NoDaLiDa)},
  editor =        {Tiedemann, J{\"o}rg and Tahmasebi, Nina},
  month =         {22--24 May},
  organization =  {Northern European Association for Language Technology
                   (NEALT)},
  pages =         {162--171},
  publisher =     {Association for Computational Linguistics},
  title =         {{KILLE}: a Framework for Situated Agents for Learning
                   Language Through Interaction},
  year =          {2017},
  url =           {https://gup.ub.gu.se/publication/253950},
}

@inproceedings{Dobnik:2006cr,
  address =       {Milton Keynes, United Kingdom},
  author =        {Dobnik, Simon},
  booktitle =     {Proceedings of the 9th Annual CLUK Research
                   Colloquium},
  month =         {March 8--9},
  organization =  {The Open University},
  pages =         {1-8},
  title =         {Learning spatial referential words with mobile
                   robots},
  year =          {2006},
  abstract =      {Natural language contains a number of word categories
                   that are referential in nature. Their full semantics
                   can only be evaluated by examining the context in
                   which the words are used. An important and
                   challenging group of words are those that describe
                   space. A system has been developed where the meanings
                   of spatial words such as near, left and behind are
                   learnt by a mobile robot from its experience of
                   environment: by abstracting over the properties of
                   its knowledge of environment and the descriptions
                   that a human commentator used to describe it.
                   Learning is performed offline using statistical and
                   symbolic learning techniques. With the knowledge that
                   it acquired the robot is able to generate new
                   descriptions of new environments. Users can query the
                   robot through a simple dialogue interface using
                   spoken natural language.},
  url =           {http://www.dobnik.net/simon/documents/cluk06.pdf},
}

@phdthesis{Dobnik:2009dz,
  address =       {Oxford, United Kingdom},
  author =        {Dobnik, Simon},
  month =         {September 4},
  school =        {University of Oxford: Faculty of Linguistics,
                   Philology and Phonetics and The Queen's College},
  title =         {Teaching mobile robots to use spatial words},
  year =          {2009},
  url =           {https://gup.ub.gu.se/publication/270997},
}

@article{Kruijff:2007,
  author =        {Kruijff, Geert-Jan M. and Zender, Hendrik and
                   Jensfelt, Patric and Christensen, Henrik I.},
  journal =       {International Journal of Advanced Robotic Systems},
  note =          {Special issue on human and robot interactive
                   communication},
  number =        {1},
  pages =         {125--138},
  title =         {Situated dialogue and spatial organization: what,
                   where... and why?},
  volume =        {4},
  year =          {2007},
  url =           {http://www.cognitivesystems.org/publications/kruijff_etal07-
                  jars.pdf},
}

@article{Zender:2008,
  author =        {Zender, Hendrik and {Mart\'{\i}nez-Mozos}, \'{O}scar and
                   Jensfelt, Patric and Kruijff, Geert-Jan M. and
                   Burgard, Wolfram},
  journal =       {Robotics and Autonomous Systems},
  month =         {June},
  note =          {Special issue ``From sensors to human spatial
                   concepts''},
  number =        {6},
  pages =         {493--502},
  title =         {Conceptual Spatial Representations for Indoor Mobile
                   Robots},
  volume =        {56},
  year =          {2008},
}

@article{Lauria:2001,
  author =        {Lauria, Stanislao and Bugmann, Guido and
                   Kyriacou, Theocharis and Bos, Johan and Klein, Ewan},
  journal =       {IEEE Intelligent Systems},
  month =         {September/October},
  pages =         {38--45},
  title =         {Training personal robots using natural language
                   instruction},
  volume =        {16},
  year =          {2001},
}

@article{LauriaEtAl:2002b,
  author =        {Lauria, Stanislao and Bugmann, Guido and
                   Kyriacou, Theocharis and Klein, Ewan},
  journal =       {Robotics and Autonomous Systems},
  number =        {3--4},
  pages =         {171--181},
  title =         {Mobile robot programming using natural language},
  volume =        {38},
  year =          {2002},
  abstract =      {How will naive users program domestic robots? This
                   paper describes the design of a practical system that
                   uses natural language to teach a vision-based robot
                   how to navigate in a miniature town. To enable
                   unconstrained speech the robot is provided with a set
                   of primitive procedures derived from a corpus of
                   route instructions. When the user refers to a route
                   that is not known to the robot, the system will learn
                   it by combining primitives as instructed by the user.
                   This paper describes the components of the
                   Instruction-Based Learning architecture and discusses
                   issues of knowledge representation, the selection of
                   primitives and the conversion of natural language
                   into robot-understandable procedures.},
  doi =           {http://dx.doi.org/10.1016/S0921-8890(02)00166-5},
}

@inproceedings{Skocaj:2010fk,
  address =       {Anchorage, AK, USA},
  author =        {Danijel Sko\v{c}aj and Miroslav Jani\v{c}ek and
                   Matej Kristan and Geert-Jan M. Kruijff and
                   Ale\v{s} Leonardis and Pierre Lison and
                   Alen Vre\v{c}ko and Michael Zillich},
  booktitle =     {ICRA 2010 workshop ICAIR - Interactive Communication
                   for Autonomous Intelligent Robots},
  pages =         {30--36},
  title =         {A basic cognitive system for interactive continuous
                   learning of visual concepts},
  year =          {2010},
  abstract =      {Interactive continuous learning is an important
                   characteristic of a cognitive agent that is supposed
                   to operate and evolve in an everchanging environment.
                   In this paper we present representations and
                   mechanisms that are necessary for continuous learning
                   of visual concepts in dialogue with a tutor. We
                   present an approach for modelling beliefs stemming
                   from multiple modalities and we show how these
                   beliefs are created by processing visual and
                   linguistic information and how they are used for
                   learning. We also present a system that exploits
                   these representations and mechanisms, and demonstrate
                   these principles in the case of learning about object
                   colours and basic shapes in dialogue with the tutor.},
}

@inproceedings{Skocaj:2011fu,
  address =       {San Francisco, CA, USA},
  author =        {Danijel Sko\v{c}aj and Matej Kristan and
                   Alen Vre\v{c}ko and Marko Mahni\v{c} and
                   Miroslav Jan\'{i}\v{c}ek and Geert-Jan M. Kruijff and
                   Marc Hanheide and Nick Hawes and Thomas Keller and
                   Michael Zillich and Kai Zhou},
  booktitle =     {IEEE/RSJ International Conference on Intelligent
                   Robots and Systems IROS 2011},
  month =         {25-30 September},
  title =         {A system for interactive learning in dialogue with a
                   tutor},
  year =          {2011},
  abstract =      {In this paper we present representations and
                   mechanisms that facilitate continuous learning of
                   visual concepts in dialogue with a tutor and show the
                   implemented robot system. We present how beliefs
                   about the world are created by processing visual and
                   linguistic information and show how they are used for
                   planning system behaviour with the aim at satisfying
                   its internal drive -- to extend its knowledge. The
                   system facilitates different kinds of learning
                   initiated by the human tutor or by the system itself.
                   We demonstrate these principles in the case of
                   learning about object colours and basic shapes.},
  url =           {http://cogx.eu/data/cogx/publications/skocajIROS11.pdf},
}

@incollection{SteelsLoetzsch:2009,
  author =        {Luc Steels and Martin Loetzsch},
  booktitle =     {Spatial Language and Dialogue},
  editor =        {Coventry, Kenny R. and Tenbrink, Thora and
                   Bateman, John. A.},
  publisher =     {Oxford University Press},
  title =         {Perspective Alignment in Spatial Language},
  year =          {2009},
}

@article{Steels:2005os,
  author =        {Steels, Luc and Belpaeme, Tony},
  journal =       {Behavioral and Brain Sciences},
  number =        {4},
  pages =         {469-489},
  title =         {Coordinating Perceptually Grounded Categories Through
                   Language: A Case Study For Colour},
  volume =        {28},
  year =          {2005},
}

@article{SteelsBaillie:2003,
  author =        {Steels, Luc and Baillie, Jean-Christophe},
  journal =       {Robotics and Autonomous Systems},
  month =         {May},
  number =        {2--3},
  pages =         {163--173},
  title =         {Shared grounding of event descriptions by autonomous
                   robots},
  volume =        {43},
  year =          {2003},
  doi =           {doi:10.1016/S0921-8890(02)00357-3},
}

@inproceedings{Schutte:2015aa,
  author =        {Sch\"{u}tte, Niels and Kelleher, John and
                   Mac Namee, Brian},
  booktitle =     {Proceedings of the Workshop on Spatial Reasoning and
                   Interaction for Real-World Robotics at the
                   International Conference on Intelligent Robots and
                   Systems (IROS-2015)},
  pages =         {4--11},
  title =         {Reformulation Strategies of Repeated References in
                   the Context of Robot Perception Errors in Situated
                   Dialogue},
  year =          {2015},
}

@incollection{LoganSadler:1996,
  address =       {Cambridge, MA},
  author =        {Logan, Gordon D. and Sadler, Daniel D.},
  booktitle =     {Language and Space},
  editor =        {Bloom, Paul and Peterson, Mary A. and Nadel, Lynn and
                   Garrett, Merrill F.},
  pages =         {493--530},
  publisher =     {MIT Press},
  title =         {A computational analysis of the apprehension of
                   spatial relations},
  year =          {1996},
}

@inproceedings{Dobnik:2017ac,
  address =       {Saarbr{\"u}cken, Germany},
  author =        {Dobnik, Simon and {\AA}stbom, Amelie},
  booktitle =     {Proceedings of {Saardial} -- Semdial 2017: The 21st
                   Workshop on the Semantics and Pragmatics of Dialogue},
  editor =        {Petukhova, Volha and Tian, Ye},
  month =         {August 15--17},
  pages =         {17--26},
  title =         {{(Perceptual)} grounding as interaction},
  year =          {2017},
  url =           {https://gup.ub.gu.se/publication/255455},
}

@article{RegierCarlson:2001,
  author =        {Regier, Terry and Carlson, Laura A.},
  journal =       {Journal of Experimental Psychology: General},
  number =        {2},
  pages =         {273--298},
  title =         {Grounding spatial language in perception: an
                   empirical and computational investigation},
  volume =        {130},
  year =          {2001},
  doi =           {10.1037//0096-3445.130.2.273},
}

@incollection{Coventry:2005ab,
  author =        {Coventry, Kenny and Garrod, Simon},
  booktitle =     {Functional features in language and space: insights
                   from perception, categorization, and development},
  editor =        {Carlson, Laura Anne and Zee, Emile van der},
  pages =         {149--162},
  publisher =     {Oxford University Press},
  title =         {Spatial prepositions and the functional geometric
                   framework. Towards a classification of
                   extra-geometric influences.},
  volume =        {2},
  year =          {2005},
}

@article{Kelleher:2009fk,
  address =       {Cambridge, MA, USA},
  author =        {Kelleher, John D. and Costello, Fintan J.},
  journal =       {Computational Linguistics},
  number =        {2},
  pages =         {271--306},
  publisher =     {MIT Press},
  title =         {Applying computational models of spatial prepositions
                   to visually situated dialog},
  volume =        {35},
  year =          {2009},
  doi =           {10.1162/coli.06-78-prep14},
  issn =          {0891-2017},
}

@inproceedings{Dobnik:2015aa,
  address =       {Gothenburg, Sweden},
  author =        {Dobnik, Simon and Howes, Christine and
                   Kelleher, John D.},
  booktitle =     {Proceedings of {goDIAL} -- Semdial 2015: The 19th
                   Workshop on the Semantics and Pragmatics of Dialogue},
  editor =        {Howes, Christine and Larsson, Staffan},
  month =         {24--26th August},
  pages =         {24--32},
  title =         {Changing perspective: Local alignment of reference
                   frames in dialogue},
  year =          {2015},
  abstract =      {In this paper we examine how people negotiate,
                   interpret and repair the frame of reference (FoR) in
                   free dialogues discussing spatial scenes. We describe
                   a pilot study in which participants are given
                   different perspectives of the same scene and asked to
                   locate several objects that are only shown on one of
                   their pictures. This task requires participants to
                   coordinate on FoR in order to identify the missing
                   objects. Preliminary results indicate that
                   conversational participants align locally on FoR but
                   do not converge on a global frame of reference.
                   Misunderstandings lead to clarification sequences in
                   which participants shift the FoR. These findings have
                   implications for situated dialogue systems.},
  url =           {https://gup.ub.gu.se/publication/224188},
}

@article{Skantze:2016aa,
  author =        {Skantze, Gabriel},
  journal =       {AI Magazine},
  number =        {4},
  pages =         {19--31},
  title =         {Real-time Coordination in Human-robot Interaction
                   using Face and Voice},
  volume =        {37},
  year =          {2016},
}

