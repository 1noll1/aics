@article{Agrawal:2017aa,
  author =        {Aishwarya Agrawal and Dhruv Batra and Devi Parikh and
                   Aniruddha Kembhavi},
  journal =       {arXiv},
  title =         {Don't Just Assume; Look and Answer: Overcoming Priors
                   for Visual Question Answering},
  volume =        {arXiv:1712.00377 [cs.CV]},
  year =          {2017},
  url =           {http://arxiv.org/abs/1712.00377},
}

@mastersthesis{Akram:2017aa,
  address =       {Stockholm, Sweden},
  author =        {Saad Ullah Akram},
  school =        {School of Computer Science and Communication, Control
                   and Robotics, Royal Institute of Technolog},
  title =         {Visual recognition of isolated Swedish sign language
                   signs},
  year =          {2012},
}

@inproceedings{Andreas:2016aa,
  address =       {San Diego, California},
  author =        {Jacob Andreas and Marcus Rohrbach and Trevor Darrell and
                   Dan Klein},
  booktitle =     {Proceedings of {NAACL-HLT} 2016},
  journal =       {CoRR},
  month =         {June 12-17},
  organization =  {Association for Computational Linguistics},
  pages =         {1545--1554},
  title =         {Learning to Compose Neural Networks for Question
                   Answering},
  year =          {2016},
  url =           {http://arxiv.org/abs/1601.01705},
}

@techreport{Astbom:2017aa,
  address =       {Gothenburg, Sweden},
  author =        {{\AA}stbom, Amelie},
  institution =   {Department of Philosophy, Linguistics and Theory of
                   Science (FLOV), University of Gothenburg},
  month =         {February 7},
  note =          {{S}upervisor: Simon Dobnik, opponent: Linnea Strand,
                   examiner: Christine Howes},
  type =          {C-uppsats (Bachelor's thesis/extended essay)},
  title =         {How function of objects affects geometry of spatial
                   descriptions. {A} study of {Swedish} and {Japanese}},
  year =          {2017},
}

@article{Barsalou:1999uq,
  author =        {Lawrence W. Barsalou},
  journal =       {Behavioral and Brain Sciences},
  pages =         {577--609},
  title =         {Perceptual symbol systems},
  volume =        {22},
  year =          {1999},
}

@article{Barsalou:2008aa,
  author =        {Barsalou, Lawrence W.},
  journal =       {Annual Review of Psychology},
  pages =         {617--645},
  title =         {Grounded cognition},
  volume =        {59},
  year =          {2008},
  abstract =      {Grounded cognition rejects traditional views that
                   cognition is computation on amodal symbols in a
                   modular system, independent of the brain's modal
                   systems for perception, action, and introspection.
                   Instead, grounded cognition proposes that modal
                   simulations, bodily states, and situated action
                   underlie cognition. Accumulating behavioral and
                   neural evidence supporting this view is reviewed from
                   research on perception, memory, knowledge, language,
                   thought, social cognition, and development. Theories
                   of grounded cognition are also reviewed, as are
                   origins of the area and common misperceptions of it.
                   Theoretical, empirical, and methodological issues are
                   raised whose future treatment is likely to affect the
                   growth and impact of grounded cognition.},
  doi =           {10.1146/annurev.psych.59.103006.093639},
  url =           {https://doi.org/10.1146/annurev.psych.59.103006.093639},
}

@article{Battaglia:2013aa,
  author =        {Battaglia, Peter W. and Hamrick, Jessica B. and
                   Tenenbaum, Joshua B.},
  journal =       {Proceedings of the National Academy of Sciences},
  number =        {45},
  pages =         {18327-18332},
  title =         {Simulation as an engine of physical scene
                   understanding},
  volume =        {110},
  year =          {2013},
  abstract =      {In a glance, we can perceive whether a stack of
                   dishes will topple, a branch will support a child's
                   weight, a grocery bag is poorly packed and liable to
                   tear or crush its contents, or a tool is firmly
                   attached to a table or free to be lifted. Such rapid
                   physical inferences are central to how people
                   interact with the world and with each other, yet
                   their computational underpinnings are poorly
                   understood. We propose a model based on an
                   ``intuitive physics engine,'' a cognitive mechanism
                   similar to computer engines that simulate rich
                   physics in video games and graphics, but that uses
                   approximate, probabilistic simulations to make robust
                   and fast inferences in complex natural scenes where
                   crucial information is unobserved. This single model
                   fits data from five distinct psychophysical tasks,
                   captures several illusions and biases, and explains
                   core aspects of human mental models and common-sense
                   reasoning that are instrumental to how humans
                   understand their everyday world.},
  doi =           {10.1073/pnas.1306572110},
  url =           {http://www.pnas.org/content/110/45/18327.abstract},
}

@book{Bradski:2008aa,
  author =        {Bradski, Gary and Kaehler, Adrian},
  publisher =     {O'Reilly Media, Inc.},
  title =         {Learning {OpenCV}: Computer vision with the {OpenCV}
                   library},
  year =          {2008},
}

@article{Bruni:2014aa,
  author =        {Bruni, Elia and Tran, Nam-Khanh and Baroni, Marco},
  journal =       {Journal of Artificial Intelligence Research (JAIR)},
  number =        {1--47},
  title =         {Multimodal Distributional Semantics},
  volume =        {49},
  year =          {2014},
}

@inproceedings{Byron:2003aa,
  author =        {Byron, Donna K},
  booktitle =     {Proceedings of the First International Workshop on
                   Language Understanding and Agents for Real World
                   Interaction},
  pages =         {39--47},
  title =         {Understanding referring expressions in situated
                   language some challenges for real-world agents},
  year =          {2003},
}

@unpublished{Cooperinprepa,
  author =        {Robin Cooper},
  note =          {Draft of book chapters available from
  \url{https://sites.google.com/site/typetheorywithrecords/drafts}},
  title =         {Type theory and language: from perception to
                   linguistic communication},
  year =          {in prep},
  url =           {https://sites.google.com/site/typetheorywithrecords/drafts},
}

@incollection{Coventry:2005aa,
  author =        {Coventry, Kenny R. and Cangelosi, Angelo and
                   Rajapakse, Rohanna and Bacon, Alison and
                   Newstead, Stephen and Joyce, Dan and
                   Richards, Lynn V.},
  booktitle =     {Spatial Cognition IV. Reasoning, Action, Interaction},
  editor =        {Freksa, Christian and Knauff, Markus and
                   Krieg-Br{\"u}ckner, Bernd and Nebel, Bernhard and
                   Barkowsky, Thomas},
  pages =         {98-110},
  publisher =     {Springer Berlin Heidelberg},
  series =        {Lecture Notes in Computer Science},
  title =         {Spatial Prepositions and Vague Quantifiers:
                   Implementing the Functional Geometric Framework},
  volume =        {3343},
  year =          {2005},
  doi =           {10.1007/978-3-540-32255-9_6},
  isbn =          {978-3-540-25048-7},
}

@incollection{Coventry:2005ab,
  author =        {Coventry, Kenny and Garrod, Simon},
  booktitle =     {Functional features in language and space: insights
                   from perception, categorization, and development},
  editor =        {Carlson, Laura Anne and Zee, Emile van der},
  pages =         {149--162},
  publisher =     {Oxford University Press},
  title =         {Spatial prepositions and the functional geometric
                   framework. Towards a classification of
                   extra-geometric influences.},
  volume =        {2},
  year =          {2005},
}

@article{Dissanayake:2001,
  author =        {Dissanayake, M. W. M. G and Newman, P. M. and
                   Durrant-Whyte, H. F. and Clark, S. and Csorba, M.},
  journal =       {IEEE Transactions on Robotic and Automation},
  number =        {3},
  pages =         {229-241},
  title =         {A solution to the simultaneous localization and map
                   building ({SLAM}) problem},
  volume =        {17},
  year =          {2001},
}

@phdthesis{Dobnik:2009dz,
  address =       {Oxford, United Kingdom},
  author =        {Dobnik, Simon},
  month =         {September 4},
  note =          {http://www.dobnik.net/simon/documents/thesis.pdf},
  school =        {University of Oxford: Faculty of Linguistics,
                   Philology and Phonetics and The Queen's College},
  title =         {Teaching mobile robots to use spatial words},
  year =          {2009},
  url =           {https://gup.ub.gu.se/publication/270997},
}

@inproceedings{Dobnik:2013aa,
  address =       {Berlin, Germany},
  author =        {Dobnik, Simon and Kelleher, John D.},
  booktitle =     {Proceedings of PRE-CogSsci 2013: Production of
                   referring expressions -- bridging the gap between
                   cognitive and computational approaches to reference},
  month =         {31 July},
  pages =         {1--6},
  title =         {Towards an automatic identification of functional and
                   geometric spatial prepositions},
  year =          {2013},
  url =           {http://pre2013.uvt.nl/pdf/dobnik-kelleher.pdf},
}

@inproceedings{Dobnik:2014aa,
  address =       {Edinburgh},
  author =        {Dobnik, Simon and Kelleher, John D. and
                   Koniaris, Christos},
  booktitle =     {Proceedings of {DialWatt} -- Semdial 2014: The 18th
                   Workshop on the Semantics and Pragmatics of Dialogue},
  editor =        {Verena Rieser and Philippe Muller},
  month =         {1--3 September},
  pages =         {43--52},
  title =         {Priming and Alignment of Frame of Reference in
                   Situated Conversation},
  year =          {2014},
  url =           {http://gup.ub.gu.se/records/fulltext/200741/200741.pdf},
}

@inproceedings{Dobnik:2014ab,
  address =       {Dublin, Ireland},
  author =        {Dobnik, Simon and Kelleher, John D.},
  booktitle =     {Proceedings of the Third V\&L Net Workshop on Vision
                   and Language},
  month =         {August},
  pages =         {33--37},
  publisher =     {Dublin City University and the Association for
                   Computational Linguistics},
  title =         {Exploration of functional semantics of prepositions
                   from corpora of descriptions of visual scenes},
  year =          {2014},
  url =           {http://www.aclweb.org/anthology/W14-5405},
}

@inproceedings{Dobnik:2015aa,
  address =       {Gothenburg, Sweden},
  author =        {Dobnik, Simon and Howes, Christine and
                   Kelleher, John D.},
  booktitle =     {Proceedings of {goDIAL} -- Semdial 2015: The 19th
                   Workshop on the Semantics and Pragmatics of Dialogue},
  editor =        {Howes, Christine and Larsson, Staffan},
  month =         {24--26th August},
  pages =         {24--32},
  title =         {Changing perspective: Local alignment of reference
                   frames in dialogue},
  year =          {2015},
  abstract =      {In this paper we examine how people negotiate,
                   interpret and repair the frame of reference (FoR) in
                   free dialogues discussing spatial scenes. We describe
                   a pilot study in which participants are given
                   different perspectives of the same scene and asked to
                   locate several objects that are only shown on one of
                   their pictures. This task requires participants to
                   coordinate on FoR in order to identify the missing
                   objects. Preliminary results indicate that
                   conversational participants align locally on FoR but
                   do not converge on a global frame of reference.
                   Misunderstandings lead to clarification sequences in
                   which participants shift the FoR. These findings have
                   implications for situated dialogue systems.},
  url =           {https://gup.ub.gu.se/publication/224188},
}

@inproceedings{Dobnik:2017aa,
  address =       {Gothenburg, Sweden},
  author =        {Dobnik, Simon and de Graaf, Erik},
  booktitle =     {Proceedings of the 21st Nordic Conference on
                   Computational Linguistics (NoDaLiDa)},
  editor =        {Tiedemann, J{\"o}rg and Tahmasebi, Nina},
  month =         {22--24 May},
  organization =  {Northern European Association for Language Technology
                   (NEALT)},
  pages =         {162--171},
  publisher =     {Association for Computational Linguistics},
  title =         {{KILLE}: a Framework for Situated Agents for Learning
                   Language Through Interaction},
  year =          {2017},
  url =           {https://gup.ub.gu.se/publication/253950},
}

@inproceedings{Dobnik:2017ac,
  address =       {Saarbr{\"u}cken, Germany},
  author =        {Dobnik, Simon and {\AA}stbom, Amelie},
  booktitle =     {Proceedings of {Saardial} -- Semdial 2017: The 21st
                   Workshop on the Semantics and Pragmatics of Dialogue},
  editor =        {Petukhova, Volha and Tian, Ye},
  month =         {August 15--17},
  pages =         {17--26},
  title =         {{(Perceptual)} grounding as interaction},
  year =          {2017},
  url =           {https://gup.ub.gu.se/publication/255455},
}

@article{Foerster:2016aa,
  author =        {Jakob N. Foerster and Yannis M. Assael and
                   Nando de Freitas and Shimon Whiteson},
  journal =       {CoRR},
  title =         {Learning to Communicate with Deep Multi-Agent
                   Reinforcement Learning},
  volume =        {abs/1605.06676},
  year =          {2016},
}

@inproceedings{Ghanimifard:2017ab,
  address =       {Montpellier, France},
  author =        {Ghanimifard, Mehdi and Dobnik, Simon},
  booktitle =     {Proceedings of {IWCS 2017}: 12th International
                   Conference on Computational Semantics},
  editor =        {Gardent, Claire and Retor\'{e}, Christian},
  month =         {September 19--22},
  pages =         {1--12},
  publisher =     {Association for Computational Linguistics},
  title =         {Learning to Compose Spatial Relations with Grounded
                   Neural Language Models},
  year =          {2017},
  abstract =      {Language is compositional: we can generate and
                   interpret novel sentences by having a notion of the
                   meaning of their individual parts. Spatial
                   descriptions are grounded in perceptional
                   representations but their meaning is also defined by
                   what neighbouring words they co-occur with. In this
                   paper, we examine how language models conditioned on
                   perceptual features can capture the semantics of
                   composed phrases as well as of individual words. We
                   generate a synthetic dataset of spatial descriptions
                   referring to perceptual scenes and examine how
                   grounded language models built with deep neural
                   networks can account for compositionality of
                   descriptions -- by evaluating how the learned
                   language models can deal with novel grounded composed
                   descriptions and novel grounded decomposed
                   descriptions, constituents previously not seen in
                   isolation.},
  url =           {https://gup.ub.gu.se/publication/257763?lang=en},
}

@article{Glenberg:1997aa,
  author =        {Glenberg, Arthur M.},
  journal =       {The Behavioral and brain sciences},
  month =         {April},
  pages =         {1--55},
  title =         {What memory is for},
  volume =        {20},
  year =          {1997},
}

@book{Goebel:2013aa,
  author =        {Patrick Goebel},
  publisher =     {Lulu},
  title =         {{ROS} by example},
  year =          {2013},
}

@mastersthesis{Graaf:2016aa,
  address =       {Gothenburg, Sweden},
  author =        {de Graaf, Erik},
  month =         {June, 8th},
  note =          {{S}upervisor: Simon Dobnik, examiner: Richard
                   Johansson, opponent: Lorena Llozhi},
  school =        {Department of Philosophy, Linguistics and Theory of
                   Science. University of Gothenburg},
  title =         {Learning Objects and Spatial Relations with {K}inect},
  year =          {2016},
  abstract =      {In order for humans to have meaningful interactions
                   with a robotic system, this system should be capable
                   of grounding semantic representations to their
                   real-world representations, learn spatial
                   relationships and communicate using spoken human
                   language. End users need to be able to query the
                   system what objects it already has knowledge of, for
                   more efficient learning. Such systems exist, but
                   require large sample sizes, thus not allowing end
                   users to teach the system more objects when needed.
                   To overcome this problem, we developed a non-mobile
                   system dubbed Kille, that uses a 3D camera, SIFT
                   features and machine learning to allow a tutor to
                   teach the system objects and spatial relations. The
                   system is built upon the ROS (Robot Operating System)
                   framework and uses Opendial software as a dialogue
                   system, for which a ROS support was written as part
                   of this project. We describe the hardware of the
                   system, the software used and developed, and we
                   evaluate its performance. Our results show that Kille
                   performs well on small learning sets, considering the
                   low sample size it uses to learn. In contrast to
                   other approaches, we focus on learning by a tutor
                   presenting objects and not by providing a dataset.
                   Recognition of spatial relations works well, however
                   no definitive conclusions can be drawn. This is
                   largely due to the small number of participants and
                   the subjective nature of spatial relations.},
}

@article{Hamilton:2014aa,
  author =        {Hamilton, Antonia F de C and Kessler, Klaus and
                   Creem-Regehr, Sarah H},
  journal =       {Frontiers in Human Neuroscience},
  month =         {June},
  number =        {403},
  pages =         {1--3},
  publisher =     {Frontiers Media S.A.},
  title =         {Perspective taking: building a neurocognitive
                   framework for integrating the ``social''and the
                   ``spatial''},
  volume =        {8},
  year =          {2014},
  doi =           {10.3389/fnhum.2014.00403},
  isbn =          {1662-5161},
  url =           {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4052522/},
}

@article{Harnad:1990,
  author =        {Harnad, Stevan},
  journal =       {Physica D},
  month =         {June},
  number =        {1--3},
  pages =         {335--346},
  title =         {The symbol grounding problem},
  volume =        {42},
  year =          {1990},
  doi =           {10.1016/0167-2789(90)90087-6},
}

@article{Jordan:2005aa,
  author =        {Jordan, Pamela W and Walker, Marilyn A},
  journal =       {Journal of Artificial Intelligence Research},
  pages =         {157--194},
  title =         {Learning content selection rules for generating
                   object descriptions in dialogue},
  volume =        {24},
  year =          {2005},
  doi =           {http://dx.doi.org/10.1613/jair.1591},
}

@inproceedings{Karpathy:2015aa,
  author =        {Karpathy, Andrej and Fei-Fei, Li},
  booktitle =     {Proceedings of the IEEE Conference on Computer Vision
                   and Pattern Recognition},
  pages =         {3128--3137},
  title =         {Deep visual-semantic alignments for generating image
                   descriptions},
  year =          {2015},
}

@article{Kelleher:2005fk,
  author =        {Kelleher, John D. and Costello, Fintan J. and
                   van Genabith, Josef},
  journal =       {Artificial Intelligence},
  pages =         {62--102},
  title =         {Dynamically Structuring Updating and Interrelating
                   Representations of Visual and Linguistic Discourse},
  volume =        {167},
  year =          {2005},
}

@article{Kelleher:2009fk,
  address =       {Cambridge, MA, USA},
  author =        {Kelleher, John D. and Costello, Fintan J.},
  journal =       {Computational Linguistics},
  number =        {2},
  pages =         {271--306},
  publisher =     {MIT Press},
  title =         {Applying computational models of spatial prepositions
                   to visually situated dialog},
  volume =        {35},
  year =          {2009},
  doi =           {10.1162/coli.06-78-prep14},
  issn =          {0891-2017},
}

@article{Kennington:2014aa,
  author =        {Kennington, Casey and Kousidis, Spyros and
                   Schlangen, David},
  journal =       {Proceedings of SIGdial 2014: Short Papers},
  title =         {{InproTKs:} A toolkit for incremental situated
                   processing},
  year =          {2014},
}

@inproceedings{Kennington:2015aa,
  address =       {Beijing, China},
  author =        {Kennington, Casey and Schlangen, David},
  booktitle =     {Proceedings of the 53rd Annual Meeting of the
                   Association for Computational Linguistics and the 7th
                   International Joint Conference on Natural Language
                   Processing (Volume 1: Long Papers)},
  month =         {July},
  pages =         {292--301},
  publisher =     {Association for Computational Linguistics},
  title =         {Simple Learning and Compositional Application of
                   Perceptually Grounded Word Meanings for Incremental
                   Reference Resolution},
  year =          {2015},
  url =           {http://www.aclweb.org/anthology/P15-1029},
}

@inproceedings{Krafka:2016aa,
  author =        {Kyle Krafka and Aditya Khosla and Petr Kellnhofer and
                   Harini Kannan and Suchendra Bhandarkar and
                   Wojciech Matusik and Antonio Torralba},
  booktitle =     {IEEE Conference on Computer Vision and Pattern
                   Recognition (CVPR)},
  title =         {Eye Tracking for Everyone},
  year =          {2016},
}

@article{Krahmer:2011aa,
  author =        {Krahmer, Emiel and van Deemter, Kees},
  journal =       {Computational Linguistics},
  number =        {1},
  pages =         {173--218},
  publisher =     {MIT Press},
  title =         {Computational Generation of Referring Expressions: A
                   Survey},
  volume =        {38},
  year =          {2011},
  isbn =          {0891-2017},
}

@article{Kruijff:2007,
  author =        {Kruijff, Geert-Jan M. and Zender, Hendrik and
                   Jensfelt, Patric and Christensen, Henrik I.},
  journal =       {International Journal of Advanced Robotic Systems},
  note =          {Special issue on human and robot interactive
                   communication},
  number =        {1},
  pages =         {125--138},
  title =         {Situated dialogue and spatial organization: what,
                   where... and why?},
  volume =        {4},
  year =          {2007},
  url =           {http://www.cognitivesystems.org/publications/kruijff_etal07-
                  jars.pdf},
}

@mastersthesis{Lang:2011aa,
  address =       {Berlin, Germany},
  author =        {Simon Lang},
  school =        {Institut f{\"u}r Informatik, Freie Universit{\"a}t
                   Berlin},
  type =          {Bachelorarbeit},
  title =         {Sign Language Recognition with Kinect},
  year =          {2011},
}

@inbook{Lang:2012aa,
  address =       {Berlin, Heidelberg},
  author =        {Lang, Simon and Block, Marco and Rojas, Ra{\'u}l},
  booktitle =     {Artificial Intelligence and Soft Computing: 11th
                   International Conference, ICAISC 2012, Zakopane,
                   Poland, April 29-May 3, 2012, Proceedings, Part I},
  editor =        {Rutkowski, Leszek and Korytkowski, Marcin and
                   Scherer, Rafa{\l} and Tadeusiewicz, Ryszard and
                   Zadeh, Lotfi A. and Zurada, Jacek M.},
  pages =         {394--402},
  publisher =     {Springer Berlin Heidelberg},
  title =         {Sign Language Recognition Using Kinect},
  year =          {2012},
  abstract =      {An open source framework for general gesture
                   recognition is presented and tested with isolated
                   signs of sign language. Other than common systems for
                   sign language recognition, this framework makes use
                   of Kinect, a depth camera which makes real-time
                   3D-reconstruction easily applicable. Recognition is
                   done using hidden Markov models with a continuous
                   observation density. The framework also offers an
                   easy way of initializing and training new gestures or
                   signs by performing them several times in front of
                   the camera. First results with a recognition rate of
                   97{\%} show that depth cameras are well-suited for
                   sign language recognition.},
  doi =           {10.1007/978-3-642-29347-4_46},
  isbn =          {978-3-642-29347-4},
}

@article{Lauria:2001,
  author =        {Lauria, Stanislao and Bugmann, Guido and
                   Kyriacou, Theocharis and Bos, Johan and Klein, Ewan},
  journal =       {IEEE Intelligent Systems},
  month =         {September/October},
  pages =         {38--45},
  title =         {Training personal robots using natural language
                   instruction},
  volume =        {16},
  year =          {2001},
}

@article{LauriaEtAl:2002b,
  author =        {Lauria, Stanislao and Bugmann, Guido and
                   Kyriacou, Theocharis and Klein, Ewan},
  journal =       {Robotics and Autonomous Systems},
  number =        {3--4},
  pages =         {171--181},
  title =         {Mobile robot programming using natural language},
  volume =        {38},
  year =          {2002},
  abstract =      {How will naive users program domestic robots? This
                   paper describes the design of a practical system that
                   uses natural language to teach a vision-based robot
                   how to navigate in a miniature town. To enable
                   unconstrained speech the robot is provided with a set
                   of primitive procedures derived from a corpus of
                   route instructions. When the user refers to a route
                   that is not known to the robot, the system will learn
                   it by combining primitives as instructed by the user.
                   This paper describes the components of the
                   Instruction-Based Learning architecture and discusses
                   issues of knowledge representation, the selection of
                   primitives and the conversion of natural language
                   into robot-understandable procedures.},
  doi =           {http://dx.doi.org/10.1016/S0921-8890(02)00166-5},
}

@article{Lazaridou:2016aa,
  author =        {Angeliki Lazaridou and Alexander Peysakhovich and
                   Marco Baroni},
  journal =       {arXiv},
  pages =         {1--11},
  title =         {Multi-Agent Cooperation and the Emergence of
                   (Natural) Language},
  volume =        {arXiv:1612.07182v2 [cs.CL]},
  year =          {2016},
  url =           {http://arxiv.org/abs/1612.07182},
}

@incollection{LoganSadler:1996,
  address =       {Cambridge, MA},
  author =        {Logan, Gordon D. and Sadler, Daniel D.},
  booktitle =     {Language and Space},
  editor =        {Bloom, Paul and Peterson, Mary A. and Nadel, Lynn and
                   Garrett, Merrill F.},
  pages =         {493--530},
  publisher =     {MIT Press},
  title =         {A computational analysis of the apprehension of
                   spatial relations},
  year =          {1996},
}

@inproceedings{Lowe:1999aa,
  author =        {Lowe, David G},
  booktitle =     {Computer vision, 1999. The proceedings of the seventh
                   IEEE international conference on},
  organization =  {IEEE},
  pages =         {1150--1157},
  title =         {Object recognition from local scale-invariant
                   features},
  volume =        {2},
  year =          {1999},
  doi =           {10.1109/ICCV.1999.790410},
}

@article{Lowe:2004aa,
  author =        {Lowe, David G},
  journal =       {International journal of computer vision},
  number =        {2},
  pages =         {91--110},
  publisher =     {Springer},
  title =         {Distinctive image features from scale-invariant
                   keypoints},
  volume =        {60},
  year =          {2004},
}

@unpublished{Lu:2016aa,
  author =        {Jiasen Lu and Caiming Xiong and Devi Parikh and
                   Richard Socher},
  month =         {6 June},
  note =          {arXiv:1612.01887 [cs.CV]},
  title =         {Knowing When to Look: Adaptive Attention via A Visual
                   Sentinel for Image Captioning},
  year =          {2017},
}

@inproceedings{Malinowski:2015aa,
  author =        {Malinowski, Mateusz and Rohrbach, Marcus and
                   Fritz, Mario},
  booktitle =     {Proceedings of the IEEE International Conference on
                   Computer Vision},
  pages =         {1--9},
  title =         {Ask your neurons: A neural-based approach to
                   answering questions about images},
  year =          {2015},
}

@book{Marr:1982aa,
  author =        {Marr, David},
  month =         {August},
  publisher =     {MIT Press Scholarship Online},
  title =         {Vision: A computational approach},
  year =          {2010},
  annote =        {This posthumously published book (1982), which
                   influenced a generation of brain and cognitive
                   scientists, inspiring many to enter the field,
                   describes a general framework for understanding
                   visual perception and touches on broader questions
                   about how the brain and its functions can be studied
                   and understood. This MIT Press edition makes this
                   work available to a new generation of students and
                   scientists. In the author's framework, the process of
                   vision constructs a set of representations, starting
                   from a description of the input image and culminating
                   with a description of three-dimensional objects in
                   the surrounding environment. A central theme, and one
                   that has had far-reaching influence in both
                   neuroscience and cognitive science, is the notion of
                   different levels of analysis---in the author's
                   framework, the computational level, the algorithmic
                   level, and the hardware implementation level. Now,
                   thirty years later, the main problems that occupied
                   the author remain fundamental open problems in the
                   study of perception. His book provides inspiration
                   for the continuing efforts to integrate knowledge
                   from cognition and computation to understand vision
                   and the brain.},
  doi =           {10.7551/mitpress/9780262514620.001.0001},
}

@inproceedings{Matuszek:2012aa,
  address =       {Edinburgh, Scotland},
  author =        {Matuszek, Cynthia and FitzGerald, Nicholas and
                   Zettlemoyer, Luke and Bo, Liefeng and Fox, Dieter},
  booktitle =     {Proceedings of the 29th International Conference on
                   Machine Learning (ICML 2012)},
  editor =        {John Langford and Joelle Pineau},
  month =         {June 27th - July 3rd},
  title =         {A joint model of language and perception for grounded
                   attribute learning},
  year =          {2012},
}

@inproceedings{Matuszek:2012uq,
  author =        {Cynthia Matuszek and Evan Herbst and Luke Zettlemoyer and
                   Dieter Fox},
  booktitle =     {Proceedings of the 13th International Symposium on
                   Experimental Robotics (ISER)},
  month =         {June},
  title =         {Learning to Parse Natural Language Commands to a
                   Robot Control System},
  year =          {2012},
}

@article{McMahan:2015aa,
  author =        {McMahan, Brian and Stone, Matthew},
  journal =       {Transactions of the Association for Computational
                   Linguistics},
  pages =         {103--115},
  title =         {A {B}ayesian model of grounded color semantics},
  volume =        {3},
  year =          {2015},
}

@inproceedings{Mei:2016aa,
  author =        {Mei, Hongyuan and Bansal, Mohit and
                   Walter, Matthew R},
  booktitle =     {AAAI},
  pages =         {2772--2778},
  title =         {Listen, Attend, and Walk: Neural Mapping of
                   Navigational Instructions to Action Sequences},
  year =          {2016},
}

@article{Monroe:2016aa,
  author =        {Will Monroe and Noah D. Goodman and
                   Christopher Potts},
  journal =       {CoRR},
  title =         {Learning to Generate Compositional Color
                   Descriptions},
  volume =        {abs/1606.03821},
  year =          {2016},
  url =           {http://arxiv.org/abs/1606.03821},
}

@article{Muja:2009aa,
  author =        {Muja, Marius and Lowe, David G},
  journal =       {VISAPP (1)},
  number =        {331--340},
  pages =         {2},
  title =         {Fast approximate nearest neighbors with automatic
                   algorithm configuration},
  volume =        {2},
  year =          {2009},
}

@inproceedings{Mustafa:2014aa,
  author =        {Mustafa, Edon and Dimopoulos, Konstantinos},
  booktitle =     {Dautov, R., Gkasis, P., \& Karama-nos, A. et
                   al.(2014). Proceedings of the 9th South East
                   EuropeanDoctoral Student Conference},
  organization =  {Thessaloniki: SEERC},
  pages =         {271--285},
  title =         {Sign Language Recognition using Kinect},
  year =          {2014},
}

@book{OKane:2013aa,
  author =        {Jason M. O'Kane},
  month =         {10},
  publisher =     {CreateSpace Independent Publishing Platform},
  title =         {A Gentle Introduction to ROS},
  year =          {2013},
  isbn =          {9781492143239},
}

@article{Pezzelle:2018aa,
  author =        {Sandro Pezzelle and Ionut{-}Teodor Sorodoc and
                   Raffaella Bernardi},
  journal =       {arXiv},
  pages =         {1--12},
  title =         {Comparatives, Quantifiers, Proportions: {A}
                   Multi-Task Model for the Learning of Quantities from
                   Vision},
  volume =        {arXiv:1804.05018 [cs.CV]},
  year =          {2018},
  url =           {http://arxiv.org/abs/1804.05018},
}

@inproceedings{Quigley:2009aa,
  author =        {Quigley, Morgan and Conley, Ken and Gerkey, Brian and
                   Faust, Josh and Foote, Tully and Leibs, Jeremy and
                   Wheeler, Rob and Ng, Andrew Y},
  booktitle =     {ICRA workshop on open source software},
  pages =         {5},
  title =         {{ROS:} an open-source Robot Operating System},
  volume =        {3},
  year =          {2009},
  url =           {http://www.ros.org/},
}

@inproceedings{Rashtchian:2010kx,
  address =       {Los Angeles, CA},
  author =        {Cyrus Rashtchian and Peter Young and Micah Hodosh and
                   Julia Hockenmaier},
  booktitle =     {Proceedings of the {NAACL HLT} 2010 {W}orkshop on
                   creating speech and language data with {Amazon's
                   Mechanical Turk}},
  month =         {6 June},
  publisher =     {North American Chapter of the Association for
                   Computational Linguistics (NAACL)},
  title =         {Collecting Image Annotations Using {Amazon's
                   Mechanical Turk}},
  year =          {2010},
}

@book{Regier:1996,
  address =       {Cambridge, Massachusetts, London, England},
  author =        {Regier, Terry},
  publisher =     {MIT Press},
  title =         {The human semantic potential: spatial language and
                   constrained connectionism},
  year =          {1996},
}

@article{RegierCarlson:2001,
  author =        {Regier, Terry and Carlson, Laura A.},
  journal =       {Journal of Experimental Psychology: General},
  number =        {2},
  pages =         {273--298},
  title =         {Grounding spatial language in perception: an
                   empirical and computational investigation},
  volume =        {130},
  year =          {2001},
  doi =           {10.1037//0096-3445.130.2.273},
}

@article{Roy:2002,
  author =        {Roy, Deb},
  journal =       {Computer speech and language},
  number =        {3},
  pages =         {353--385},
  title =         {Learning visually-grounded words and syntax for a
                   scene description task},
  volume =        {16},
  year =          {2002},
  abstract =      {A spoken language generation system has been
                   developed that learns to describe objects in
                   computer-generated visual scenes. The system is
                   trained by a show-and-tell' procedure in which visual
                   scenes are paired with natural language descriptions.
                   Learning algorithms acquire probabilistic structures
                   which encode the visual semantics of phrase
                   structure, word classes, and individual words. Using
                   these structures, a planning algorithm integrates
                   syntactic, semantic, and contextual constraints to
                   generate natural and unambiguous descriptions of
                   objects in novel scenes. The system generates
                   syntactically well-formed compound adjective noun
                   phrases, as well as relative spatial clauses. The
                   acquired linguistic structures generalize from
                   training data, enabling the production of novel word
                   sequences which were never observed during training.
                   The output of the generation system is synthesized
                   using word-based concatenative synthesis drawing from
                   the original training speech corpus. In evaluations
                   of semantic comprehension by human judges, the
                   performance of automatically generated spoken
                   descriptions was comparable to human-generated
                   descriptions. This work is motivated by our long-term
                   goal of developing spoken language processing systems
                   which grounds semantics in machine perception and
                   action.},
}

@article{Roy:2005,
  address =       {Essex, UK},
  author =        {Roy, Deb},
  journal =       {Artificial Intelligence},
  month =         {September},
  number =        {1-2},
  pages =         {170--205},
  publisher =     {Elsevier Science Publishers Ltd.},
  title =         {Semiotic schemas: a framework for grounding language
                   in action and perception},
  volume =        {167},
  year =          {2005},
  doi =           {10.1016/j.artint.2005.04.007},
  issn =          {0004-3702},
}

@inproceedings{Skantze:2012aa,
  author =        {Skantze, Gabriel and Al Moubayed, Samer},
  booktitle =     {Proceedings of the 14th ACM international conference
                   on Multimodal interaction},
  organization =  {ACM},
  pages =         {69--76},
  title =         {{IrisTK}: a statechart-based toolkit for multi-party
                   face-to-face interaction},
  year =          {2012},
}

@article{Skantze:2014aa,
  author =        {Skantze, Gabriel and Hjalmarsson, Anna and
                   Oertel, Catharine},
  journal =       {Speech Communication},
  pages =         {50--66},
  publisher =     {Elsevier},
  title =         {Turn-taking, feedback and joint attention in situated
                   human-robot interaction},
  volume =        {65},
  year =          {2014},
  abstract =      {In this paper, we present a study where a robot
                   instructs a human on how to draw a route on a map.
                   The human and robot are seated face-to-face with the
                   map placed on the table between them. The user's and
                   the robot's gaze can thus serve several simultaneous
                   functions: as cues to joint attention, turn-taking,
                   level of understanding and task progression. We have
                   compared this face-to-face setting with a setting
                   where the robot employs a random gaze behaviour, as
                   well as a voice-only setting where the robot is
                   hidden behind a paper board. In addition to this, we
                   have also manipulated turn-taking cues such as
                   completeness and filled pauses in the robot's speech.
                   By analysing the participants' subjective rating,
                   task completion, verbal responses, gaze behaviour,
                   and drawing activity, we show that the users indeed
                   benefit from the robot's gaze when talking about
                   landmarks, and that the robot's verbal and gaze
                   behaviour has a strong effect on the users'
                   turn-taking behaviour. We also present an analysis of
                   the users' gaze and lexical and prosodic realisation
                   of feedback after the robot instructions, and show
                   that these cues reveal whether the user has yet
                   executed the previous instruction, as well as the
                   user's level of uncertainty.},
}

@article{Skantze:2016aa,
  author =        {Skantze, Gabriel},
  journal =       {AI Magazine},
  number =        {4},
  pages =         {19--31},
  title =         {Real-time Coordination in Human-robot Interaction
                   using Face and Voice},
  volume =        {37},
  year =          {2016},
}

@inproceedings{Skocaj:2010fk,
  address =       {Anchorage, AK, USA},
  author =        {Danijel Sko\v{c}aj and Miroslav Jani\v{c}ek and
                   Matej Kristan and Geert-Jan M. Kruijff and
                   Ale\v{s} Leonardis and Pierre Lison and
                   Alen Vre\v{c}ko and Michael Zillich},
  booktitle =     {ICRA 2010 workshop ICAIR - Interactive Communication
                   for Autonomous Intelligent Robots},
  pages =         {30--36},
  title =         {A basic cognitive system for interactive continuous
                   learning of visual concepts},
  year =          {2010},
  abstract =      {Interactive continuous learning is an important
                   characteristic of a cognitive agent that is supposed
                   to operate and evolve in an everchanging environment.
                   In this paper we present representations and
                   mechanisms that are necessary for continuous learning
                   of visual concepts in dialogue with a tutor. We
                   present an approach for modelling beliefs stemming
                   from multiple modalities and we show how these
                   beliefs are created by processing visual and
                   linguistic information and how they are used for
                   learning. We also present a system that exploits
                   these representations and mechanisms, and demonstrate
                   these principles in the case of learning about object
                   colours and basic shapes in dialogue with the tutor.},
}

@inproceedings{Skocaj:2011fu,
  address =       {San Francisco, CA, USA},
  author =        {Danijel Sko\v{c}aj and Matej Kristan and
                   Alen Vre\v{c}ko and Marko Mahni\v{c} and
                   Miroslav Jan\'{i}\v{c}ek and Geert-Jan M. Kruijff and
                   Marc Hanheide and Nick Hawes and Thomas Keller and
                   Michael Zillich and Kai Zhou},
  booktitle =     {IEEE/RSJ International Conference on Intelligent
                   Robots and Systems IROS 2011},
  month =         {25-30 September},
  title =         {A system for interactive learning in dialogue with a
                   tutor},
  year =          {2011},
  abstract =      {In this paper we present representations and
                   mechanisms that facilitate continuous learning of
                   visual concepts in dialogue with a tutor and show the
                   implemented robot system. We present how beliefs
                   about the world are created by processing visual and
                   linguistic information and show how they are used for
                   planning system behaviour with the aim at satisfying
                   its internal drive -- to extend its knowledge. The
                   system facilitates different kinds of learning
                   initiated by the human tutor or by the system itself.
                   We demonstrate these principles in the case of
                   learning about object colours and basic shapes.},
  url =           {http://cogx.eu/data/cogx/publications/skocajIROS11.pdf},
}

@article{Steels:2005os,
  author =        {Steels, Luc and Belpaeme, Tony},
  journal =       {Behavioral and Brain Sciences},
  number =        {4},
  pages =         {469-489},
  title =         {Coordinating Perceptually Grounded Categories Through
                   Language: A Case Study For Colour},
  volume =        {28},
  year =          {2005},
}

@article{SteelsBaillie:2003,
  author =        {Steels, Luc and Baillie, Jean-Christophe},
  journal =       {Robotics and Autonomous Systems},
  month =         {May},
  number =        {2--3},
  pages =         {163--173},
  title =         {Shared grounding of event descriptions by autonomous
                   robots},
  volume =        {43},
  year =          {2003},
  doi =           {doi:10.1016/S0921-8890(02)00357-3},
}

@incollection{SteelsLoetzsch:2009,
  author =        {Luc Steels and Martin Loetzsch},
  booktitle =     {Spatial Language and Dialogue},
  editor =        {Coventry, Kenny R. and Tenbrink, Thora and
                   Bateman, John. A.},
  publisher =     {Oxford University Press},
  title =         {Perspective Alignment in Spatial Language},
  year =          {2009},
}

@inproceedings{Stoia:2006zr,
  address =       {Sydney, Australia},
  author =        {Stoia, Laura and Shockley, Darla Magdalene and
                   Byron, Donna K. and Fosler-Lussier, Eric},
  booktitle =     {Proceedings of the Fourth International Natural
                   Language Generation Conference},
  month =         {July},
  pages =         {81--88},
  publisher =     {Association for Computational Linguistics},
  title =         {Noun Phrase Generation for Situated Dialogs},
  year =          {2006},
}

@article{Tenenbaum:2011ly,
  author =        {Tenenbaum, Joshua B. and Kemp, Charles and
                   Griffiths, Thomas L. and Goodman, Noah D.},
  journal =       {Science},
  number =        {6022},
  pages =         {1279-1285},
  title =         {How to Grow a Mind: Statistics, Structure, and
                   Abstraction},
  volume =        {331},
  year =          {2011},
  abstract =      {In coming to understand the world‚{\"A}{\^\i}in
                   learning concepts, acquiring language, and grasping
                   causal relations‚{\"A}{\^\i}our minds make
                   inferences that appear to go far beyond the data
                   available. How do we do it? This review describes
                   recent approaches to reverse-engineering human
                   learning and cognitive development and, in parallel,
                   engineering more humanlike machine learning systems.
                   Computational models that perform probabilistic
                   inference over hierarchies of flexibly structured
                   representations can address some of the deepest
                   questions about the nature and origins of human
                   thought: How does abstract knowledge guide learning
                   and reasoning from sparse data? What forms does our
                   knowledge take, across different domains and tasks?
                   And how is that abstract knowledge itself acquired?},
  doi =           {10.1126/science.1192788},
}

@inproceedings{Viethen:2011aa,
  author =        {Viethen, Jette and Dale, Robert and Guhe, Markus},
  booktitle =     {Proceedings of the Conference on Empirical Methods in
                   Natural Language Processing},
  organization =  {Association for Computational Linguistics},
  pages =         {1158--1167},
  title =         {Generating subsequent reference in shared visual
                   scenes: Computation vs. re-use},
  year =          {2011},
}

@inproceedings{Viethen:2011ab,
  author =        {Viethen, Jette and Dale, Robert and Guhe, Markus},
  booktitle =     {Proceedings of the 13th European Workshop on Natural
                   Language Generation},
  organization =  {Association for Computational Linguistics},
  pages =         {44--52},
  title =         {The impact of visual context on the content of
                   referring expressions},
  year =          {2011},
}

@article{Wang:2016aa,
  author =        {Wang, Sida I and Liang, Percy and
                   Manning, Christopher D},
  journal =       {arXiv preprint arXiv:1606.02447},
  title =         {Learning Language Games through Interaction},
  year =          {2016},
}

@article{Winograd:1972,
  author =        {Winograd, Terry},
  journal =       {Cognitive Psychology},
  number =        {1},
  publisher =     {Edinburgh University Press},
  title =         {Understanding Natural Language},
  volume =        {3},
  year =          {1972},
}

@book{Winograd:1976,
  author =        {Winograd, Terry},
  publisher =     {Edinburgh University Press},
  title =         {Understanding Natural Language},
  year =          {1976},
}

@inproceedings{Xu:2015aa,
  author =        {Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and
                   Courville, Aaron and Salakhutdinov, Ruslan and
                   Zemel, Richard and Bengio, Yoshua},
  booktitle =     {arXiv preprint},
  month =         {February 11},
  number =        {arXiv:1502.03044v3 [cs.LG]},
  pages =         {1--22},
  title =         {Show, attend and tell: Neural image caption
                   generation with visual attention},
  year =          {2015},
}

@article{Yang:2014aa,
  author =        {Yang, Hee-Deok},
  journal =       {Sensors},
  number =        {1},
  pages =         {135--147},
  publisher =     {Multidisciplinary Digital Publishing Institute},
  title =         {Sign language recognition with the kinect sensor
                   based on conditional random fields},
  volume =        {15},
  year =          {2014},
}

@article{Zender:2008,
  author =        {Zender, Hendrik and {Mart\'{\i}nez-Mozos}, \'{O}scar and
                   Jensfelt, Patric and Kruijff, Geert-Jan M. and
                   Burgard, Wolfram},
  journal =       {Robotics and Autonomous Systems},
  month =         {June},
  note =          {Special issue ``From sensors to human spatial
                   concepts''},
  number =        {6},
  pages =         {493--502},
  title =         {Conceptual Spatial Representations for Indoor Mobile
                   Robots},
  volume =        {56},
  year =          {2008},
}

@article{Zender:2012uq,
  address =       {Los Alamitos, CA, USA},
  author =        {H. Zender and M. Janicek and Geert-Jan Kruijff},
  journal =       {IEEE Intelligent Systems},
  number =        {2},
  pages =         {27--35},
  publisher =     {IEEE Computer Society},
  title =         {Situated communication for joint activity in
                   human-robot teams},
  volume =        {27},
  year =          {2012},
  doi =               {http://doi.ieeecomputersociety.org/10.1109/MIS.2012.8},
  issn =          {1541-1672},
}

