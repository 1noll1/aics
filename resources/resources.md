
# Resources

This folder contains some resources (code and datasets) useful for your project.

## Lecture 2: pyTTR

  - [pyTTR](https://github.com/GU-CLASP/pyttr/blob/master/ttr-overview-aics2019.ipynb) is an implementation of TTR in Python
  - An application of pyTTR code to image classification with DNNs and visual question answering: A. Matsson, S. Dobnik, and S. Larsson. ImageTTR: Grounding Type Theory with Records in image classification for visual question answering. In R. Osswald, C. Retoré, and P. Sutton, editors, Proceedings of the IWCS 2019 Workshop on Computing Semantics with Types, Frames and Related Structures, pages 55–64, Gothenburg, Sweden, June 2019. Association for Computational Linguistics. [paper](https://www.aclweb.org/anthology/W19-1007/) and [code](https://github.com/arildm/imagettr) The paper is based on Arild's masters thesis which is turn is based on his AICS course project.



## Image classification

  - [Basic classification: Classify images of clothing](https://www.tensorflow.org/tutorials/keras/classification)
  - [Building powerful image classification models using very little data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)
  - [How to Develop a Deep Learning Photo Caption Generator from Scratch](https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/)



## Local

  - Code
  - Datasets: 
	  * https://www.kaggle.com/datasets
	  * http://llcao.net/cu-deeplearning15/resource.html
	  * Spatial relations and referring expressions: GR3D3 corpus of http://web.science.mq.edu.au/~jviethen/spatial/index.html
	  * Spatial relations and referring expressions: GR3D3 and GR3D7 corpus http://jetteviethen.net/research/spatial.html
	  * Generating referring expressions, the Tuna corpus: http://www.csd.abdn.ac.uk/research/tuna/
	  * Several corpora on GRE from Margaret Mitchell: http://www.m-mitchell.com/corpora.html
  - References:
      * GRE: http://web.science.mq.edu.au/~jviethen/GREbib.php
  - A list of vision and language corpora from the iV&L consortium (very good): https://ivl-net.eu/repositories/data-resources/
  - A list of code from the iV&L consortium: https://ivl-net.eu/repositories/software-resources/
   
  


## External
  
  - https://github.com/kjw0612/awesome-deep-vision
  - A vision and language course with a good list of resources: http://llcao.net/cu-deeplearning15/resource.html
  - https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html
  - https://machinelearningmastery.com/prepare-photo-caption-dataset-training-deep-learning-model/
  - https://cs.stanford.edu/people/karpathy/deepimagesent/
  - https://cs.stanford.edu/people/karpathy/sfmltalk.pdf
  - https://github.com/anuragmishracse/caption_generator
  - https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/
  
  
